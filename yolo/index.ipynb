{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv5\n",
    "\n",
    "Official documentation: <https://docs.ultralytics.com/yolov5/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ROOT = os.environ.get('PROJECT_ROOT')\n",
    "file = ROOT + 'content/fish.yaml'\n",
    "img_size = 640 # must be a multiple of 32\n",
    "device = 'cpu' # 'cuda device, i.e. 0 or 0,1,2,3 or cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "<https://docs.ultralytics.com/yolov5/tutorials/train_custom_data/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = 'yolov5s.pt'\n",
    "epochs = 300\n",
    "project_test = ROOT + 'content/runs'\n",
    "\n",
    "!python yolov5/train.py \\\n",
    "    --data={file} \\\n",
    "    --weights={weights} \\\n",
    "    --epochs={epochs} \\\n",
    "    --imgsz={img_size} \\\n",
    "    --name='baw' \\\n",
    "    --device={device} \\\n",
    "    --cache='ram' \\\n",
    "    --project={project_test}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "After training you can copy the latest weights from `content/runs/baw[X]/weights/best.pt` to `content/current.pt` and run the following command to test the model.\n",
    "\n",
    "<https://github.com/ultralytics/yolov5/blob/master/val.py>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mdata=/Users/btree-mac/Repos/baw-fish-cell-yolo/content/fish.yaml, weights=['/Users/btree-mac/Repos/baw-fish-cell-yolo/content/current.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=test, device=cpu, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=/Users/btree-mac/Repos/baw-fish-cell-yolo/content/runs, name=test, exist_ok=False, half=False, dnn=False\n",
      "YOLOv5 ðŸš€ v7.0-178-ga199480 Python-3.11.4 torch-2.0.1 CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7012822 parameters, 0 gradients, 15.8 GFLOPs\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mScanning /Users/btree-mac/Repos/baw-fish-cell-yolo/content/dataset/labels/\u001b[0m\n",
      "\u001b[34m\u001b[1mtest: \u001b[0mNew cache created: /Users/btree-mac/Repos/baw-fish-cell-yolo/content/dataset/labels/test.cache\n",
      "                 Class     Images  Instances          P          R      mAP50   \n",
      "                   all          9        596      0.961      0.909      0.962      0.488\n",
      "Speed: 17.5ms pre-process, 385.5ms inference, 6.2ms NMS per image at shape (32, 3, 640, 640)\n",
      "Results saved to \u001b[1m/Users/btree-mac/Repos/baw-fish-cell-yolo/content/runs/test4\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "current_weights = ROOT + 'yolo/content/current.pt'\n",
    "project_test = ROOT + 'yolo/content/runs'\n",
    "\n",
    "!python yolov5/val.py \\\n",
    "    --weights={current_weights} \\\n",
    "    --data={file} \\\n",
    "    --imgsz={img_size} \\\n",
    "    --name='test' \\\n",
    "    --task='test' \\\n",
    "    --device='cpu' \\\n",
    "    --project={project_test}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction / Interfence\n",
    "\n",
    "<https://docs.ultralytics.com/yolov5/quickstart_tutorial/#inference-with-detectpy>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference = ROOT + 'content/inference/input/'\n",
    "output = ROOT + 'content/inference/output/'\n",
    "\n",
    "!python yolov5/detect.py \\\n",
    "    --weights={current_weights} \\\n",
    "    --imgsz={img_size} \\\n",
    "    --source={inference} \\\n",
    "    --name='exp' \\\n",
    "    --save-txt \\\n",
    "    --project={output}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert YoloV5 to tf.js\n",
    "\n",
    "To be able to use our trained model in the frontend, we need to convert it to TensorFlow Javascript format. This can be done by running the following command:\n",
    "\n",
    "(Hint: you may need to set `export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python\n",
    "!python yolov5/export.py --weights content/current.pt  --include tfjs --topk-per-class 300 --topk-all 300"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d676b7253dcf0d89b32ca27fa5769379356d94cf4d42312d801c4f2e8d17292e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
